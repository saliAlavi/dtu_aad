{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ad9d6d6-56c3-46ad-8a42-779bddd7f235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scipy in /users/PAS2301/alialavi/.local/lib/python3.6/site-packages (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /users/PAS2301/alialavi/.local/lib/python3.6/site-packages (from scipy) (1.19.5)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow-datasets in /users/PAS2301/alialavi/.local/lib/python3.6/site-packages (4.5.2)\n",
      "Requirement already satisfied: tqdm in /users/PAS2301/alialavi/.local/lib/python3.6/site-packages (from tensorflow-datasets) (4.64.1)\n",
      "Requirement already satisfied: six in /apps/project/ondemand/app_jupyter/3.1.18/lib/python3.6/site-packages (from tensorflow-datasets) (1.16.0)\n",
      "Requirement already satisfied: promise in /users/PAS2301/alialavi/.local/lib/python3.6/site-packages (from tensorflow-datasets) (2.3)\n",
      "Requirement already satisfied: absl-py in /users/PAS2301/alialavi/.local/lib/python3.6/site-packages (from tensorflow-datasets) (0.12.0)\n",
      "Requirement already satisfied: importlib-resources in /users/PAS2301/alialavi/.local/lib/python3.6/site-packages (from tensorflow-datasets) (5.4.0)\n",
      "Requirement already satisfied: typing-extensions in /apps/project/ondemand/app_jupyter/3.1.18/lib/python3.6/site-packages (from tensorflow-datasets) (4.1.1)\n",
      "Requirement already satisfied: dill in /users/PAS2301/alialavi/.local/lib/python3.6/site-packages (from tensorflow-datasets) (0.3.4)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in /users/PAS2301/alialavi/.local/lib/python3.6/site-packages (from tensorflow-datasets) (3.19.6)\n",
      "Requirement already satisfied: tensorflow-metadata in /users/PAS2301/alialavi/.local/lib/python3.6/site-packages (from tensorflow-datasets) (1.2.0)\n",
      "Requirement already satisfied: dataclasses in /apps/project/ondemand/app_jupyter/3.1.18/lib/python3.6/site-packages (from tensorflow-datasets) (0.8)\n",
      "Requirement already satisfied: termcolor in /users/PAS2301/alialavi/.local/lib/python3.6/site-packages (from tensorflow-datasets) (1.1.0)\n",
      "Requirement already satisfied: numpy in /users/PAS2301/alialavi/.local/lib/python3.6/site-packages (from tensorflow-datasets) (1.19.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /apps/project/ondemand/app_jupyter/3.1.18/lib/python3.6/site-packages (from tensorflow-datasets) (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /apps/project/ondemand/app_jupyter/3.1.18/lib/python3.6/site-packages (from requests>=2.19.0->tensorflow-datasets) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /apps/project/ondemand/app_jupyter/3.1.18/lib/python3.6/site-packages (from requests>=2.19.0->tensorflow-datasets) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /apps/project/ondemand/app_jupyter/3.1.18/lib/python3.6/site-packages (from requests>=2.19.0->tensorflow-datasets) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /apps/project/ondemand/app_jupyter/3.1.18/lib/python3.6/site-packages (from requests>=2.19.0->tensorflow-datasets) (2.0.12)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /apps/project/ondemand/app_jupyter/3.1.18/lib/python3.6/site-packages (from importlib-resources->tensorflow-datasets) (3.6.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /users/PAS2301/alialavi/.local/lib/python3.6/site-packages (from tensorflow-metadata->tensorflow-datasets) (1.56.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Using cached tensorflow-2.6.2-cp36-cp36m-manylinux2010_x86_64.whl (458.3 MB)\n",
      "\u001b[33mWARNING: tensorflow 2.6.2 does not provide the extra 'and-cuda'\u001b[0m\n",
      "Collecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp36-cp36m-manylinux1_x86_64.whl (4.0 MB)\n",
      "     |████████████████████████████████| 4.0 MB 2.4 MB/s            \n",
      "\u001b[?25hCollecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "     |████████████████████████████████| 1.1 MB 44.0 MB/s            \n",
      "\u001b[?25hCollecting keras<2.7,>=2.6.0\n",
      "  Using cached keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Collecting six~=1.15.0\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorflow-estimator<2.7,>=2.6.0\n",
      "  Using cached tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "     |████████████████████████████████| 132 kB 86.5 MB/s            \n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.37.0\n",
      "  Using cached grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorboard<2.7,>=2.6.0\n",
      "  Using cached tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting numpy~=1.19.2\n",
      "  Using cached numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "Collecting clang~=5.0\n",
      "  Using cached clang-5.0.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting wheel~=0.35\n",
      "  Using cached wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Using cached wrapt-1.12.1.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cached-property\n",
      "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Using cached google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Collecting setuptools>=41.0.0\n",
      "  Using cached setuptools-59.6.0-py3-none-any.whl (952 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "     |████████████████████████████████| 144 kB 39.9 MB/s            \n",
      "\u001b[?25hCollecting idna<4,>=2.5\n",
      "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "     |████████████████████████████████| 70 kB 7.3 MB/s             \n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "     |████████████████████████████████| 167 kB 40.4 MB/s            \n",
      "\u001b[?25hCollecting charset-normalizer~=2.0.0\n",
      "  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting dataclasses\n",
      "  Using cached dataclasses-0.8-py3-none-any.whl (19 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Using cached pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[31mERROR: Will not install to the user site because it will lack sys.path precedence to six in /apps/project/ondemand/app_jupyter/3.1.18/lib/python3.6/site-packages\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy\n",
    "!pip install tensorflow-datasets\n",
    "!pip install tensorflow[and-cuda] --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1094d75-6e29-4f38-8510-b163c6c3d09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***************************************************************\n",
      "Failed to import TensorFlow. Please note that TensorFlow is not installed by default when you install TFDS. This allow you to choose to install either `tf-nightly` or `tensorflow`. Please install the most recent version of TensorFlow, by following instructions at https://tensorflow.org/install.\n",
      "***************************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8d3b0da070a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# needs to happen before anything else, since the imports below will try to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# import tensorflow, too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0mtf_compat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_tf_install\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_datasets/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtf_compat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_tf_install\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# pylint:disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_datasets/core/tf_compat.py\u001b[0m in \u001b[0;36mensure_tf_install\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m  \u001b[0;31m# pylint: disable=import-outside-toplevel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# Print more informative error message, then reraise.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "970bd529-1906-4fa6-814c-cecb0d2d2ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir =\"/fs/ess/PAS2301/alialavi/datasets/kuleuven\"\n",
    "subject=1\n",
    "fn_eeg = os.path.join(base_dir, f'preprocessed_data/S{subject}.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76c7232a-116d-4339-8adf-d0ea2b47a009",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_eeg = scipy.io.loadmat(fn_eeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc14578f-2256-4e9c-aed4-f119e1a16e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial=0\n",
    "len(f_eeg['preproc_trials'][0][trial][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2417fa3a-d920-40ef-b31c-c255c6bcca49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24896"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f_eeg['preproc_trials'][0][trial][0][0][11][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6dc3338-c510-4b20-a46e-f3379e085534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f_eeg['preproc_trials'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d007ab0-a7c1-499e-b326-9939d707d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr=f_eeg['preproc_trials'][0][trial][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6971321f-dfe8-430d-a827-fc4f45cd94b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['R'], dtype='<U1')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "557de048-79d4-43e7-bb5a-1da40d76a636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24896"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tr[0][0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a5befe97-ea10-4851-8ed8-f5316ef10fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24896"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tr[11][0,0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4b7d5b7-7ce9-44e8-a4a1-f6c6381e2b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24896, 1, 2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr[11][0,0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e5605577-ed01-48d2-a362-4e6bea12fde7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-175ff1ba3c24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train[:20%]'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwith_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tfds' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_name = ['kuleuven_50ov_5s']\n",
    "dataset_sub_name = [f'all_e1' ]\n",
    "dataset_name_full = f'{dataset_name}/{dataset_sub_name}'\n",
    "train_splits = ['train[20%:]']\n",
    "test_splits = ['train[:20%]']\n",
    "                               \n",
    "(ds_train, ds_test), dataset_info = tfds.load(dataset_name_full, split=[train_split, test_split], shuffle_files=False,with_info=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8446fcab-9ace-4038-93f1-334e664bcb6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
